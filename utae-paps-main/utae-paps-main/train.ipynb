{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e94ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from convlstm import ConvLSTM, BConvLSTM\n",
    "from ltae import LTAE2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ffc8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        encoder_widths=[64, 64, 64, 128],\n",
    "        decoder_widths=[32, 32, 64, 128],\n",
    "        out_conv=[32, 20],\n",
    "        str_conv_k=4,\n",
    "        str_conv_s=2,\n",
    "        str_conv_p=1,\n",
    "        agg_mode=\"att_group\",\n",
    "        encoder_norm=\"group\",\n",
    "        n_head=16,\n",
    "        d_model=256,\n",
    "        d_k=4,\n",
    "        encoder=False,\n",
    "        return_maps=False,\n",
    "        pad_value=0,\n",
    "        padding_mode=\"reflect\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        U-TAE architecture for spatio-temporal encoding of satellite image time series.\n",
    "        Args:\n",
    "            input_dim (int): Number of channels in the input images.\n",
    "            encoder_widths (List[int]): List giving the number of channels of the successive encoder_widths of the convolutional encoder.\n",
    "            This argument also defines the number of encoder_widths (i.e. the number of downsampling steps +1)\n",
    "            in the architecture.\n",
    "            The number of channels are given from top to bottom, i.e. from the highest to the lowest resolution.\n",
    "            decoder_widths (List[int], optional): Same as encoder_widths but for the decoder. The order in which the number of\n",
    "            channels should be given is also from top to bottom. If this argument is not specified the decoder\n",
    "            will have the same configuration as the encoder.\n",
    "            out_conv (List[int]): Number of channels of the successive convolutions for the\n",
    "            str_conv_k (int): Kernel size of the strided up and down convolutions.\n",
    "            str_conv_s (int): Stride of the strided up and down convolutions.\n",
    "            str_conv_p (int): Padding of the strided up and down convolutions.\n",
    "            agg_mode (str): Aggregation mode for the skip connections. Can either be:\n",
    "                - att_group (default) : Attention weighted temporal average, using the same\n",
    "                channel grouping strategy as in the LTAE. The attention masks are bilinearly\n",
    "                resampled to the resolution of the skipped feature maps.\n",
    "                - att_mean : Attention weighted temporal average,\n",
    "                 using the average attention scores across heads for each date.\n",
    "                - mean : Temporal average excluding padded dates.\n",
    "            encoder_norm (str): Type of normalisation layer to use in the encoding branch. Can either be:\n",
    "                - group : GroupNorm (default)\n",
    "                - batch : BatchNorm\n",
    "                - instance : InstanceNorm\n",
    "            n_head (int): Number of heads in LTAE.\n",
    "            d_model (int): Parameter of LTAE\n",
    "            d_k (int): Key-Query space dimension\n",
    "            encoder (bool): If true, the feature maps instead of the class scores are returned (default False)\n",
    "            return_maps (bool): If true, the feature maps instead of the class scores are returned (default False)\n",
    "            pad_value (float): Value used by the dataloader for temporal padding.\n",
    "            padding_mode (str): Spatial padding strategy for convolutional layers (passed to nn.Conv2d).\n",
    "        \"\"\"\n",
    "        super(UTAE, self).__init__()\n",
    "        self.n_stages = len(encoder_widths)\n",
    "        self.return_maps = return_maps\n",
    "        self.encoder_widths = encoder_widths\n",
    "        self.decoder_widths = decoder_widths\n",
    "        self.enc_dim = (\n",
    "            decoder_widths[0] if decoder_widths is not None else encoder_widths[0]\n",
    "        )\n",
    "        self.stack_dim = (\n",
    "            sum(decoder_widths) if decoder_widths is not None else sum(encoder_widths)\n",
    "        )\n",
    "        self.pad_value = pad_value\n",
    "        self.encoder = encoder\n",
    "        if encoder:\n",
    "            self.return_maps = True\n",
    "\n",
    "        if decoder_widths is not None:\n",
    "            assert len(encoder_widths) == len(decoder_widths)\n",
    "            assert encoder_widths[-1] == decoder_widths[-1]\n",
    "        else:\n",
    "            decoder_widths = encoder_widths\n",
    "\n",
    "        self.in_conv = ConvBlock(\n",
    "            nkernels=[input_dim] + [encoder_widths[0], encoder_widths[0]],\n",
    "            pad_value=pad_value,\n",
    "            norm=encoder_norm,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            DownConvBlock(\n",
    "                d_in=encoder_widths[i],\n",
    "                d_out=encoder_widths[i + 1],\n",
    "                k=str_conv_k,\n",
    "                s=str_conv_s,\n",
    "                p=str_conv_p,\n",
    "                pad_value=pad_value,\n",
    "                norm=encoder_norm,\n",
    "                padding_mode=padding_mode,\n",
    "            )\n",
    "            for i in range(self.n_stages - 1)\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            UpConvBlock(\n",
    "                d_in=decoder_widths[i],\n",
    "                d_out=decoder_widths[i - 1],\n",
    "                d_skip=encoder_widths[i - 1],\n",
    "                k=str_conv_k,\n",
    "                s=str_conv_s,\n",
    "                p=str_conv_p,\n",
    "                norm=\"batch\",\n",
    "                padding_mode=padding_mode,\n",
    "            )\n",
    "            for i in range(self.n_stages - 1, 0, -1)\n",
    "        )\n",
    "        self.temporal_encoder = LTAE2d(\n",
    "            in_channels=encoder_widths[-1],\n",
    "            d_model=d_model,\n",
    "            n_head=n_head,\n",
    "            mlp=[d_model, encoder_widths[-1]],\n",
    "            return_att=True,\n",
    "            d_k=d_k,\n",
    "        )\n",
    "        self.temporal_aggregator = Temporal_Aggregator(mode=agg_mode)\n",
    "        self.out_conv = ConvBlock(nkernels=[decoder_widths[0]] + out_conv, padding_mode=padding_mode)\n",
    "\n",
    "    def forward(self, input, batch_positions=None, return_att=False):\n",
    "        pad_mask = (\n",
    "            (input == self.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n",
    "        )  # BxT pad mask\n",
    "        out = self.in_conv.smart_forward(input)\n",
    "        feature_maps = [out]\n",
    "        # SPATIAL ENCODER\n",
    "        for i in range(self.n_stages - 1):\n",
    "            out = self.down_blocks[i].smart_forward(feature_maps[-1])\n",
    "            feature_maps.append(out)\n",
    "        # TEMPORAL ENCODER\n",
    "        out, att = self.temporal_encoder(\n",
    "            feature_maps[-1], batch_positions=batch_positions, pad_mask=pad_mask\n",
    "        )\n",
    "        # SPATIAL DECODER\n",
    "        if self.return_maps:\n",
    "            maps = [out]\n",
    "        for i in range(self.n_stages - 1):\n",
    "            skip = self.temporal_aggregator(\n",
    "                feature_maps[-(i + 2)], pad_mask=pad_mask, attn_mask=att\n",
    "            )\n",
    "            out = self.up_blocks[i](out, skip)\n",
    "            if self.return_maps:\n",
    "                maps.append(out)\n",
    "\n",
    "        if self.encoder:\n",
    "            return out, maps\n",
    "        else:\n",
    "            out = self.out_conv(out)\n",
    "            if return_att:\n",
    "                return out, att\n",
    "            if self.return_maps:\n",
    "                return out, maps\n",
    "            else:\n",
    "                return out\n",
    "\n",
    "\n",
    "class TemporallySharedBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module for convolutional encoding blocks that are shared across a sequence.\n",
    "    This module adds the self.smart_forward() method the the block.\n",
    "    smart_forward will combine the batch and temporal dimension of an input tensor\n",
    "    if it is 5-D and apply the shared convolutions to all the (batch x temp) positions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pad_value=None):\n",
    "        super(TemporallySharedBlock, self).__init__()\n",
    "        self.out_shape = None\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "    def smart_forward(self, input):\n",
    "        if len(input.shape) == 4:\n",
    "            return self.forward(input)\n",
    "        else:\n",
    "            b, t, c, h, w = input.shape\n",
    "\n",
    "            if self.pad_value is not None:\n",
    "                dummy = torch.zeros(input.shape, device=input.device).float()\n",
    "                self.out_shape = self.forward(dummy.view(b * t, c, h, w)).shape\n",
    "\n",
    "            out = input.view(b * t, c, h, w)\n",
    "            if self.pad_value is not None:\n",
    "                pad_mask = (out == self.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n",
    "                if pad_mask.any():\n",
    "                    temp = (\n",
    "                        torch.ones(\n",
    "                            self.out_shape, device=input.device, requires_grad=False\n",
    "                        )\n",
    "                        * self.pad_value\n",
    "                    )\n",
    "                    temp[~pad_mask] = self.forward(out[~pad_mask])\n",
    "                    out = temp\n",
    "                else:\n",
    "                    out = self.forward(out)\n",
    "            else:\n",
    "                out = self.forward(out)\n",
    "            _, c, h, w = out.shape\n",
    "            out = out.view(b, t, c, h, w)\n",
    "            return out\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nkernels,\n",
    "        norm=\"batch\",\n",
    "        k=3,\n",
    "        s=1,\n",
    "        p=1,\n",
    "        n_groups=4,\n",
    "        last_relu=True,\n",
    "        padding_mode=\"reflect\",\n",
    "    ):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        layers = []\n",
    "        if norm == \"batch\":\n",
    "            nl = nn.BatchNorm2d\n",
    "        elif norm == \"instance\":\n",
    "            nl = nn.InstanceNorm2d\n",
    "        elif norm == \"group\":\n",
    "            nl = lambda num_feats: nn.GroupNorm(\n",
    "                num_channels=num_feats,\n",
    "                num_groups=n_groups,\n",
    "            )\n",
    "        else:\n",
    "            nl = None\n",
    "        for i in range(len(nkernels) - 1):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=nkernels[i],\n",
    "                    out_channels=nkernels[i + 1],\n",
    "                    kernel_size=k,\n",
    "                    padding=p,\n",
    "                    stride=s,\n",
    "                    padding_mode=padding_mode,\n",
    "                )\n",
    "            )\n",
    "            if nl is not None:\n",
    "                layers.append(nl(nkernels[i + 1]))\n",
    "\n",
    "            if last_relu:\n",
    "                layers.append(nn.ReLU())\n",
    "            elif i < len(nkernels) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class ConvBlock(TemporallySharedBlock):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nkernels,\n",
    "        pad_value=None,\n",
    "        norm=\"batch\",\n",
    "        last_relu=True,\n",
    "        padding_mode=\"reflect\",\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__(pad_value=pad_value)\n",
    "        self.conv = ConvLayer(\n",
    "            nkernels=nkernels,\n",
    "            norm=norm,\n",
    "            last_relu=last_relu,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class DownConvBlock(TemporallySharedBlock):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in,\n",
    "        d_out,\n",
    "        k,\n",
    "        s,\n",
    "        p,\n",
    "        pad_value=None,\n",
    "        norm=\"batch\",\n",
    "        padding_mode=\"reflect\",\n",
    "    ):\n",
    "        super(DownConvBlock, self).__init__(pad_value=pad_value)\n",
    "        self.down = ConvLayer(\n",
    "            nkernels=[d_in, d_in],\n",
    "            norm=norm,\n",
    "            k=k,\n",
    "            s=s,\n",
    "            p=p,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "        self.conv1 = ConvLayer(\n",
    "            nkernels=[d_in, d_out],\n",
    "            norm=norm,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "        self.conv2 = ConvLayer(\n",
    "            nkernels=[d_out, d_out],\n",
    "            norm=norm,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.down(input)\n",
    "        out = self.conv1(out)\n",
    "        out = out + self.conv2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, d_out, k, s, p, norm=\"batch\", d_skip=None, padding_mode=\"reflect\"\n",
    "    ):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        d = d_out if d_skip is None else d_skip\n",
    "        self.skip_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=d, out_channels=d, kernel_size=1),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=d_in, out_channels=d_out, kernel_size=k, stride=s, padding=p\n",
    "            ),\n",
    "            nn.BatchNorm2d(d_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv1 = ConvLayer(\n",
    "            nkernels=[d_out + d, d_out], norm=norm, padding_mode=padding_mode\n",
    "        )\n",
    "        self.conv2 = ConvLayer(\n",
    "            nkernels=[d_out, d_out], norm=norm, padding_mode=padding_mode\n",
    "        )\n",
    "\n",
    "    def forward(self, input, skip):\n",
    "        out = self.up(input)\n",
    "        out = torch.cat([out, self.skip_conv(skip)], dim=1)\n",
    "        out = self.conv1(out)\n",
    "        out = out + self.conv2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Temporal_Aggregator(nn.Module):\n",
    "    def __init__(self, mode=\"mean\"):\n",
    "        super(Temporal_Aggregator, self).__init__()\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x, pad_mask=None, attn_mask=None):\n",
    "        if pad_mask is not None and pad_mask.any():\n",
    "            if self.mode == \"att_group\":\n",
    "                n_heads, b, t, h, w = attn_mask.shape\n",
    "                attn = attn_mask.view(n_heads * b, t, h, w)\n",
    "\n",
    "                if x.shape[-2] > w:\n",
    "                    attn = nn.Upsample(\n",
    "                        size=x.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                    )(attn)\n",
    "                else:\n",
    "                    attn = nn.AvgPool2d(kernel_size=w // x.shape[-2])(attn)\n",
    "\n",
    "                attn = attn.view(n_heads, b, t, *x.shape[-2:])\n",
    "                attn = attn * (~pad_mask).float()[None, :, :, None, None]\n",
    "\n",
    "                out = torch.stack(x.chunk(n_heads, dim=2))  # hxBxTxC/hxHxW\n",
    "                out = attn[:, :, :, None, :, :] * out\n",
    "                out = out.sum(dim=2)  # sum on temporal dim -> hxBxC/hxHxW\n",
    "                out = torch.cat([group for group in out], dim=1)  # -> BxCxHxW\n",
    "                return out\n",
    "            elif self.mode == \"att_mean\":\n",
    "                attn = attn_mask.mean(dim=0)  # average over heads -> BxTxHxW\n",
    "                attn = nn.Upsample(\n",
    "                    size=x.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                )(attn)\n",
    "                attn = attn * (~pad_mask).float()[:, :, None, None]\n",
    "                out = (x * attn[:, :, None, :, :]).sum(dim=1)\n",
    "                return out\n",
    "            elif self.mode == \"mean\":\n",
    "                out = x * (~pad_mask).float()[:, :, None, None, None]\n",
    "                out = out.sum(dim=1) / (~pad_mask).sum(dim=1)[:, None, None, None]\n",
    "                return out\n",
    "        else:\n",
    "            if self.mode == \"att_group\":\n",
    "                n_heads, b, t, h, w = attn_mask.shape\n",
    "                attn = attn_mask.view(n_heads * b, t, h, w)\n",
    "                if x.shape[-2] > w:\n",
    "                    attn = nn.Upsample(\n",
    "                        size=x.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                    )(attn)\n",
    "                else:\n",
    "                    attn = nn.AvgPool2d(kernel_size=w // x.shape[-2])(attn)\n",
    "                attn = attn.view(n_heads, b, t, *x.shape[-2:])\n",
    "                out = torch.stack(x.chunk(n_heads, dim=2))  # hxBxTxC/hxHxW\n",
    "                out = attn[:, :, :, None, :, :] * out\n",
    "                out = out.sum(dim=2)  # sum on temporal dim -> hxBxC/hxHxW\n",
    "                out = torch.cat([group for group in out], dim=1)  # -> BxCxHxW\n",
    "                return out\n",
    "            elif self.mode == \"att_mean\":\n",
    "                attn = attn_mask.mean(dim=0)  # average over heads -> BxTxHxW\n",
    "                attn = nn.Upsample(\n",
    "                    size=x.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "                )(attn)\n",
    "                out = (x * attn[:, :, None, :, :]).sum(dim=1)\n",
    "                return out\n",
    "            elif self.mode == \"mean\":\n",
    "                return x.mean(dim=1)\n",
    "\n",
    "\n",
    "class RecUNet(nn.Module):\n",
    "    \"\"\"Recurrent U-Net architecture. Similar to the U-TAE architecture but\n",
    "    the L-TAE is replaced by a recurrent network\n",
    "    and temporal averages are computed for the skip connections.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        encoder_widths=[64, 64, 64, 128],\n",
    "        decoder_widths=[32, 32, 64, 128],\n",
    "        out_conv=[32, 20],\n",
    "        str_conv_k=4,\n",
    "        str_conv_s=2,\n",
    "        str_conv_p=1,\n",
    "        temporal=\"lstm\",\n",
    "        input_size=128,\n",
    "        encoder_norm=\"group\",\n",
    "        hidden_dim=128,\n",
    "        encoder=False,\n",
    "        padding_mode=\"reflect\",\n",
    "        pad_value=0,\n",
    "    ):\n",
    "        super(RecUNet, self).__init__()\n",
    "        self.n_stages = len(encoder_widths)\n",
    "        self.temporal = temporal\n",
    "        self.encoder_widths = encoder_widths\n",
    "        self.decoder_widths = decoder_widths\n",
    "        self.enc_dim = (\n",
    "            decoder_widths[0] if decoder_widths is not None else encoder_widths[0]\n",
    "        )\n",
    "        self.stack_dim = (\n",
    "            sum(decoder_widths) if decoder_widths is not None else sum(encoder_widths)\n",
    "        )\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "        self.encoder = encoder\n",
    "        if encoder:\n",
    "            self.return_maps = True\n",
    "        else:\n",
    "            self.return_maps = False\n",
    "\n",
    "        if decoder_widths is not None:\n",
    "            assert len(encoder_widths) == len(decoder_widths)\n",
    "            assert encoder_widths[-1] == decoder_widths[-1]\n",
    "        else:\n",
    "            decoder_widths = encoder_widths\n",
    "\n",
    "        self.in_conv = ConvBlock(\n",
    "            nkernels=[input_dim] + [encoder_widths[0], encoder_widths[0]],\n",
    "            pad_value=pad_value,\n",
    "            norm=encoder_norm,\n",
    "        )\n",
    "\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            DownConvBlock(\n",
    "                d_in=encoder_widths[i],\n",
    "                d_out=encoder_widths[i + 1],\n",
    "                k=str_conv_k,\n",
    "                s=str_conv_s,\n",
    "                p=str_conv_p,\n",
    "                pad_value=pad_value,\n",
    "                norm=encoder_norm,\n",
    "                padding_mode=padding_mode,\n",
    "            )\n",
    "            for i in range(self.n_stages - 1)\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            UpConvBlock(\n",
    "                d_in=decoder_widths[i],\n",
    "                d_out=decoder_widths[i - 1],\n",
    "                d_skip=encoder_widths[i - 1],\n",
    "                k=str_conv_k,\n",
    "                s=str_conv_s,\n",
    "                p=str_conv_p,\n",
    "                norm=encoder_norm,\n",
    "                padding_mode=padding_mode,\n",
    "            )\n",
    "            for i in range(self.n_stages - 1, 0, -1)\n",
    "        )\n",
    "        self.temporal_aggregator = Temporal_Aggregator(mode=\"mean\")\n",
    "\n",
    "        if temporal == \"mean\":\n",
    "            self.temporal_encoder = Temporal_Aggregator(mode=\"mean\")\n",
    "        elif temporal == \"lstm\":\n",
    "            size = int(input_size / str_conv_s ** (self.n_stages - 1))\n",
    "            self.temporal_encoder = ConvLSTM(\n",
    "                input_dim=encoder_widths[-1],\n",
    "                input_size=(size, size),\n",
    "                hidden_dim=hidden_dim,\n",
    "                kernel_size=(3, 3),\n",
    "            )\n",
    "            self.out_convlstm = nn.Conv2d(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=encoder_widths[-1],\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            )\n",
    "        elif temporal == \"blstm\":\n",
    "            size = int(input_size / str_conv_s ** (self.n_stages - 1))\n",
    "            self.temporal_encoder = BConvLSTM(\n",
    "                input_dim=encoder_widths[-1],\n",
    "                input_size=(size, size),\n",
    "                hidden_dim=hidden_dim,\n",
    "                kernel_size=(3, 3),\n",
    "            )\n",
    "            self.out_convlstm = nn.Conv2d(\n",
    "                in_channels=2 * hidden_dim,\n",
    "                out_channels=encoder_widths[-1],\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            )\n",
    "        elif temporal == \"mono\":\n",
    "            self.temporal_encoder = None\n",
    "        self.out_conv = ConvBlock(nkernels=[decoder_widths[0]] + out_conv, padding_mode=padding_mode)\n",
    "\n",
    "    def forward(self, input, batch_positions=None):\n",
    "        pad_mask = (\n",
    "            (input == self.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n",
    "        )  # BxT pad mask\n",
    "\n",
    "        out = self.in_conv.smart_forward(input)\n",
    "\n",
    "        feature_maps = [out]\n",
    "        # ENCODER\n",
    "        for i in range(self.n_stages - 1):\n",
    "            out = self.down_blocks[i].smart_forward(feature_maps[-1])\n",
    "            feature_maps.append(out)\n",
    "\n",
    "        # Temporal encoder\n",
    "        if self.temporal == \"mean\":\n",
    "            out = self.temporal_encoder(feature_maps[-1], pad_mask=pad_mask)\n",
    "        elif self.temporal == \"lstm\":\n",
    "            _, out = self.temporal_encoder(feature_maps[-1], pad_mask=pad_mask)\n",
    "            out = out[0][1]  # take last cell state as embedding\n",
    "            out = self.out_convlstm(out)\n",
    "        elif self.temporal == \"blstm\":\n",
    "            out = self.temporal_encoder(feature_maps[-1], pad_mask=pad_mask)\n",
    "            out = self.out_convlstm(out)\n",
    "        elif self.temporal == \"mono\":\n",
    "            out = feature_maps[-1]\n",
    "\n",
    "        if self.return_maps:\n",
    "            maps = [out]\n",
    "        for i in range(self.n_stages - 1):\n",
    "            if self.temporal != \"mono\":\n",
    "                skip = self.temporal_aggregator(\n",
    "                    feature_maps[-(i + 2)], pad_mask=pad_mask\n",
    "                )\n",
    "            else:\n",
    "                skip = feature_maps[-(i + 2)]\n",
    "            out = self.up_blocks[i](out, skip)\n",
    "            if self.return_maps:\n",
    "                maps.append(out)\n",
    "\n",
    "        if self.encoder:\n",
    "            return out, maps\n",
    "        else:\n",
    "            out = self.out_conv(out)\n",
    "            if self.return_maps:\n",
    "                return out, maps\n",
    "            else:\n",
    "                return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf5a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
